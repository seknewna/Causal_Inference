{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzvRornRYz9y"
      },
      "source": [
        "# Tutorial 2: Firedrake + ML\n",
        "#### Author: Nacime Bouziani"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBw_GMTA3Hn3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import firedrake\n",
        "except ImportError:\n",
        "    !wget \"https://fem-on-colab.github.io/releases/firedrake-install-release-real.sh\" -O \"/tmp/firedrake-install.sh\" && bash \"/tmp/firedrake-install.sh\"\n",
        "    import firedrake\n",
        "\n",
        "from firedrake import *\n",
        "from firedrake.adjoint import *\n",
        "from firedrake.ml.pytorch import *\n",
        "from firedrake.pyplot import triplot, tripcolor, streamplot\n",
        "\n",
        "continue_annotation()\n",
        "\n",
        "try:\n",
        "  import physics_driven_ml\n",
        "except:\n",
        "  !git clone https://github.com/NBoulle/physics-driven-ml.git /content/physics-driven-ml\n",
        "  !pip install -e /content/physics-driven-ml\n",
        "  sys.path.append(\"/content/physics-driven-ml\")\n",
        "  import physics_driven_ml\n",
        "\n",
        "from physics_driven_ml.dataset_processing import StokesDataset\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import Module, ModuleList, Sequential, Linear, ReLU\n",
        "\n",
        "try:\n",
        "  from torch_geometric.nn import MessagePassing\n",
        "except:\n",
        "  !pip install torch_geometric\n",
        "  from torch_geometric.nn import MessagePassing\n",
        "\n",
        "# Download mesh and dataset\n",
        "!wget -P stokes_tutorial -c https://github.com/nbouziani/physics-driven-ml/raw/dev/data/datasets/meshes/stokes_cylinder.msh\n",
        "!wget -P stokes_tutorial -c https://github.com/nbouziani/physics-driven-ml/raw/dev/data/datasets/stokes_tutorial/data.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUMrlJQxK7le"
      },
      "source": [
        "In this tutorial, we employ a physics-driven ML approach that uses GNN to study the flow around a circular cylinder, a well-known test case in CFD. We consider the Stokes equations, which are a simpler version of the Navier-Stokes equations. The Stokes problem is a linear and time-independent PDE problem widely studied.\n",
        "\n",
        "We are interested in devising a GNN model $\\psi$ to learn the following operator:\n",
        "\n",
        "$$\\psi : f ↦ sol$$\n",
        "\n",
        "where $sol := (u, p)$ is the solution of the following Stokes problem parametrised by a source term $f$:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "- \\Delta u + \\nabla p &= f \\quad \\text{ on } \\Omega\\\\\n",
        "\\nabla \\cdot u &= 0 \\quad \\text{ on } \\Omega\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "with $\\Omega$ the domain where the problem is posed, and where $u$ and $p$ refer to the velocity field and pressure, respectively. We further equip our PDE problem with boundary conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMsTJUCB55Bm"
      },
      "source": [
        "## Physical problem: flow around a circular cylinder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVzhV49E5vj-"
      },
      "outputs": [],
      "source": [
        "# Import mesh\n",
        "mesh = Mesh(\"stokes_tutorial/stokes_cylinder.msh\")\n",
        "\n",
        "# Define mesh labels\n",
        "inlet = 1\n",
        "circle = 4\n",
        "bottom_top = (3, 5)\n",
        "\n",
        "# Plot mesh\n",
        "fig, axes = plt.subplots(1, 1, figsize=(15, 5))\n",
        "triplot(mesh, axes=axes);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBP9dbL26Y0m"
      },
      "source": [
        "### Stokes problem\n",
        "\n",
        "We can now define the Stokes problem using the Firedrake finite element software (Ham et al., 2023)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Y4zxIS7uBI"
      },
      "source": [
        "#### Define the PDE problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPXABTUz6aOg"
      },
      "outputs": [],
      "source": [
        "# TODO: Define the function spaces, we are going to use piecewise quadratic elements for the velocity and piecewise linear elements for the pressure\n",
        "V = ...\n",
        "W = ...\n",
        "Z = ...\n",
        "\n",
        "# Define source term\n",
        "f = Function(V)\n",
        "\n",
        "# TODO: Define the boundary conditions: u = (1, 0) at the inlet, u = (0, 0) at the top and bottom boundaries, and no-slip at the cylinder\n",
        "g = ...\n",
        "bcs = ...\n",
        "\n",
        "# Set nullspace\n",
        "nullspace = MixedVectorSpaceBasis(Z, [Z.sub(0), VectorSpaceBasis(constant=True)])\n",
        "\n",
        "# Define solution\n",
        "up = Function(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKvsyuA27Sm0"
      },
      "outputs": [],
      "source": [
        "# Solve the PDE\n",
        "sol_exact = Function(Z)\n",
        "\n",
        "# TODO: Define the trial and test functions\n",
        "u, p = ...\n",
        "v, q = ...\n",
        "\n",
        "# TODO: Write down the weak form of the PDE\n",
        "a = ...\n",
        "L = ...\n",
        "\n",
        "solve(a == L,\n",
        "      sol_exact,\n",
        "      bcs=bcs,\n",
        "      nullspace=nullspace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMPJGP0k7S2i"
      },
      "outputs": [],
      "source": [
        "# Helper function to plot\n",
        "def plot_sol(w):\n",
        "    u, p = w.subfunctions\n",
        "    fig, axes = plt.subplots(1, 1, figsize=(15, 5))\n",
        "    streamlines = streamplot(u, resolution=1/3, seed=0, axes=axes)\n",
        "    fig.colorbar(streamlines, ax=axes, fraction=0.046)\n",
        "    axes.set_title(\"u\")\n",
        "\n",
        "    u1, u2 = u.sub(0), u.sub(1)\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n",
        "    c = tripcolor(u1, cmap=\"jet\", axes=axes[0])\n",
        "    plt.colorbar(c)\n",
        "    axes[0].set_title(\"$u_1$\")\n",
        "    c = tripcolor(u2, cmap=\"jet\", axes=axes[1])\n",
        "    plt.colorbar(c)\n",
        "    axes[1].set_title(\"$u_2$\")\n",
        "\n",
        "    c = tripcolor(p, cmap=\"jet\", axes=axes[2])\n",
        "    plt.colorbar(c)\n",
        "    axes[2].set_title(\"p\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhJaSrYe9vpQ"
      },
      "outputs": [],
      "source": [
        "plot_sol(sol_exact)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq7IsJn8CV2"
      },
      "source": [
        "#### Define the physical constraint\n",
        "\n",
        "We want to incorporate physical prior knowledge into our machine learning model. For that we use the interface introduced in (Bouziani & Ham, 2023), to\n",
        "incorporate a physical constraint, implemented in Firedrake, into the training loss in a similar manner than PINNs. We define that constraint as the residual form associated with the PDE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzs8GURI7dg4"
      },
      "outputs": [],
      "source": [
        "# Residual assembly\n",
        "def assemble_residual(sol, f):\n",
        "    u, p = split(sol)\n",
        "    F = ... # TODO: Define the residual\n",
        "    return ... # TODO: Assemble the residual with the boundary conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFud1ZEp-AOJ"
      },
      "outputs": [],
      "source": [
        "# Define physics-driven constraint\n",
        "sol = Function(Z)\n",
        "f = Function(V)\n",
        "with set_working_tape() as _:\n",
        "    # Define PyTorch operator for assembling the residual of the PDE\n",
        "    F = ReducedFunctional(assemble_residual(sol, f), [Control(sol), Control(f)])\n",
        "    G = torch_operator(F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYkX3gHP8hLB"
      },
      "source": [
        "## Message Passing Neural Network (MPNN)\n",
        "\n",
        "We want to build a Graph Neural Network that follows the Encode-Process-Decode ([Battaglia et al., 2018](https://arxiv.org/abs/1806.01261)) while using a Message Passing Neural Network as processor. We first define the encoder and decoder using a single linear layer:\n",
        "\n",
        "- Encoder:\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "E :\\ &\\mathbb{R}^{n} → \\mathbb{R}^{l}\\\\\n",
        "& x ↦ Wx + b\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "- Decoder:\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "D :\\ &\\mathbb{R}^{l} → \\mathbb{R}^{m}\\\\\n",
        "& x ↦ Wx + b\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$\n",
        "with $W$ and $b$ learnable parameters, and where $n$, $l$, and $m$ refer to the input, latent, and output dimensions, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5XyTXxZHGLv"
      },
      "outputs": [],
      "source": [
        "class Encoder(Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        # TODO: Define the encoder network\n",
        "        self.encoder = ...\n",
        "\n",
        "    def forward(self, f):\n",
        "        \"\"\"Apply the encoder to the input f\"\"\"\n",
        "        # TODO: Define the forward pass\n",
        "        return ...\n",
        "\n",
        "\n",
        "class Decoder(Module):\n",
        "    def __init__(self, latent_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        # TODO: Define the decoder network\n",
        "        self.decoder = ...\n",
        "\n",
        "    def forward(self, h):\n",
        "        \"\"\"Apply the decoder to the latent feature vector h\"\"\"\n",
        "        # TODO: Define the forward pass\n",
        "        return ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0QJ1coVHEIf"
      },
      "source": [
        "We now need to implement the MPNN corresponding to the processor. For this we implement a model with the following simple update rule:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "  m^{n}_{ij} &= \\phi_{e}(h^{n}_{i}, h^{n}_{j} - h^{n}_{i}) \\\\\n",
        "  h^{n+1}_{i} &= \\phi_{v}\\left(h^{n}_{i}, \\frac{1}{|N_{i}|}\\sum\\limits_{j \\in N_{i}} m^{n}_{ij}\\right)\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "where $\\phi_{e}$ and $\\phi_{v}$ are MLPs. For implementing this, we use the PyTorch geometric library (PyG). In a similar manner than Graph Networks, we compose several blocks of our architecture to form the processor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjZaS6U08o4L"
      },
      "outputs": [],
      "source": [
        "class MPNN(MessagePassing):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim):\n",
        "        # Set the aggregation function as the mean (permutation-invariant)\n",
        "        super(MPNN, self).__init__(aggr=\"mean\")\n",
        "        # TODO: Define ϕe as a sequential model with two linear layers (2x input_dim -> latent_dim -> latent_dim) and ReLU activation\n",
        "        self.message_mlp = Sequential(...)\n",
        "        # TODO: Define ϕv as a sequential model with three linear layers (input_dim + latent_dim -> latent_dim -> latent_dim // 2 -> output_dim) and ReLU activations\n",
        "        self.update_mlp = Sequential(...)\n",
        "\n",
        "    def forward(self, h, edge_index):\n",
        "        return self.propagate(edge_index, h=h)\n",
        "\n",
        "    def message(self, h_i, h_j):\n",
        "        \"\"\"Compute the messages m_{ij} given the feature vectors h_{i} and h_{j}.\"\"\"\n",
        "        # TODO: Define the message function\n",
        "        m = ...\n",
        "        return self.message_mlp(m)\n",
        "\n",
        "    def update(self, message, h):\n",
        "        \"\"\"Compute the update\"\"\"\n",
        "        z = torch.cat([h, message], dim=-1)\n",
        "        return self.update_mlp(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juOFmJ3c-Qah"
      },
      "outputs": [],
      "source": [
        "# Do not change this block\n",
        "class NeuralPDESolver(Module):\n",
        "    def __init__(self, input_dim, latent_dim, output_dim, num_features, latent_features=2, nlayers=1):\n",
        "        super(NeuralPDESolver, self).__init__()\n",
        "        self.nlayers = nlayers\n",
        "        # Encoder\n",
        "        print(\"input_dim: %s latent_dim: %s output_dim: %s\" % (num_features, latent_features, num_features))\n",
        "        self.encoder = Encoder(input_dim=input_dim, latent_dim=latent_dim)\n",
        "        # Processor\n",
        "        self.processor_layers = ModuleList(modules=[MPNN(input_dim=num_features,\n",
        "                                                         latent_dim=latent_features,\n",
        "                                                         output_dim=num_features)\n",
        "                                                    for _ in range(self.nlayers)])\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(latent_dim=latent_dim, output_dim=output_dim)\n",
        "\n",
        "    def forward(self, f, edge_index):\n",
        "        # Encoding\n",
        "        h = self.encoder(f)[..., None]\n",
        "        # Processing\n",
        "        for layer in self.processor_layers:\n",
        "            h = layer(h, edge_index)\n",
        "        # Decoding\n",
        "        sol = self.decoder(h[..., 0])\n",
        "        return sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx3pWvX5-Qoq"
      },
      "outputs": [],
      "source": [
        "model = NeuralPDESolver(input_dim=V.dim(),\n",
        "                        latent_dim= V.dim(),\n",
        "                        num_features=1,\n",
        "                        output_dim=Z.dim(),\n",
        "                        nlayers=4)\n",
        "# Set double precision (default Firedrake type)\n",
        "model.double()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVtrCHEZy3SU"
      },
      "outputs": [],
      "source": [
        "M = MPNN(input_dim=1, latent_dim=2, output_dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3WxKP2Ky_e5"
      },
      "outputs": [],
      "source": [
        "M.message_mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82EzboNb-aEP"
      },
      "source": [
        "## Training using the physical constraint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_JH3pGy-fur"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1dvmqu_-ihI"
      },
      "outputs": [],
      "source": [
        "train_dataset = StokesDataset(dataset=\"stokes_tutorial\")\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, collate_fn=train_dataset.collate, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE0VoLPp-jHx"
      },
      "source": [
        "### Define evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suogji1N-fOZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    \"\"\"Evaluate the model on a given dataset.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_error = 0.0\n",
        "    for step_num, batch in enumerate(dataloader):\n",
        "\n",
        "        f, sol_exact = batch.f, batch.u\n",
        "        edge_index = batch.edge_index\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # TODO: Evaluate the model and computes the mean squared error between the solution and the exact solution\n",
        "            sol = ...\n",
        "            total_error += ...\n",
        "\n",
        "    total_error /= step_num + 1\n",
        "    return total_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlU-QzpP-3-7"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlhrLjxUJi3S"
      },
      "source": [
        "We can now train our model. For this we use the physics-driven constraint implemented in Firedrake previously defined (Bouziani & Ham, 2023). We use the following loss:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\mathcal{L} = \\|sol - sol_{exact}\\|_{\\ell_{2}}^{2} + \\alpha \\|F(f, u)\\|^{2}_{\\ell_{2}}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "with $sol_{exact}$ and $sol = (u, p)$ the predicted and exact solutions of the Stokes problem, respectively. $F$ is the residual form associated with our PDE problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROfFcdP6Yz93"
      },
      "outputs": [],
      "source": [
        "# Define the loss function\n",
        "def loss_fn(f, sol, sol_exact, alpha):\n",
        "  # Assemble residual\n",
        "  residual = ...\n",
        "  # Compute the loss\n",
        "  loss = ...\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIHaXl_2-Sj_"
      },
      "outputs": [],
      "source": [
        "def training(loss_fn):\n",
        "  # Set hyperparameters\n",
        "  epochs = 80\n",
        "  learning_rate = 5e-5\n",
        "  train_steps = len(train_dataloader)\n",
        "  best_error = 0.0\n",
        "  alpha = 0.2\n",
        "\n",
        "  # Set optimiser\n",
        "  optimiser = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Training lopp\n",
        "  for epoch in range(epochs + 1):\n",
        "      model.train()\n",
        "      # Loop over dataset\n",
        "      total_loss = 0.0\n",
        "      for step_num, batch in enumerate(train_dataloader):\n",
        "          model.zero_grad()\n",
        "\n",
        "          # Retrieve data from batch\n",
        "          f, sol_exact = batch.f, batch.u\n",
        "          edge_index = batch.edge_index\n",
        "\n",
        "          # TODO: Forward pass through the model\n",
        "          sol = ...\n",
        "\n",
        "          # TODO: Compute the loss\n",
        "          loss = ...\n",
        "          total_loss += loss.item()\n",
        "\n",
        "          # Backpropagate\n",
        "          loss.backward()\n",
        "          # Optimiser step\n",
        "          optimiser.step()\n",
        "\n",
        "      # Compute error\n",
        "      test_error = evaluate(model, train_dataloader)\n",
        "      print(f\"Epoch: {epoch} : Training loss: {total_loss/train_steps} Error (l2): {test_error}\")\n",
        "\n",
        "      if test_error < best_error or epoch == 0:\n",
        "          best_error = test_error\n",
        "          saved_model = model\n",
        "\n",
        "  print(f\"\\n Best error: {best_error:.3e}\")\n",
        "  return sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrsRmYawWODj"
      },
      "outputs": [],
      "source": [
        "sol = training(loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL9FYkK1_Jei"
      },
      "outputs": [],
      "source": [
        "# Convert PyTorch tensor to Firedrake\n",
        "sol_fd = from_torch(sol, Z)\n",
        "# Plot\n",
        "plot_sol(sol_fd)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}